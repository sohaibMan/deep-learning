# Lab 1 Report

## Goal:
The overarching aim of this lab is to foster proficiency in leveraging the PyTorch library for conducting Classification and Regression tasks, employing advanced architectures like Deep Neural Networks (DNN) and Multi-Layer Perceptrons (MLP).

## Part One: Regression
### Dataset:
- [NYSE Stock Prices](https://www.kaggle.com/datasets/dgawlik/nyse)

### Accomplishments:
1. **Exploratory Data Analysis (EDA):**
    - Executed comprehensive EDA techniques to gain profound insights into the dataset, visualizing key features and their distributions.

2. **Deep Neural Network Architecture:**
    - Engineered a robust DNN architecture in PyTorch for the regression task, incorporating pertinent features from the dataset.

3. **Hyperparameter Tuning with GridSearch:**
    - Employed GridSearch from the sklearn library to identify optimal hyperparameters, including learning rate, optimizers, epoch count, and model architecture, leading to an optimized model.

4. **Visualization:**
    - Illustrated Loss vs. Epochs and Accuracy vs. Epochs through plotted graphs for both training and test data.
    - Offered interpretations based on discerned trends in the visualizations.

5. **Regularization Techniques:**
    - Implemented diverse regularization techniques on the architecture.
    - Conducted a comparative analysis between results obtained with the initial, non-regularized model.

## Part Two: Multi-Class Classification
### Dataset:
- [Machine Predictive Maintenance](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification)

### Accomplishments:
1. **Data Preprocessing:**
    - Applied robust preprocessing techniques for cleaning and standardization/normalization of the data.
    - Ensured categorical variables were appropriately encoded, rendering the dataset ready for analysis.

2. **Exploratory Data Analysis (EDA):**
    - Executed EDA procedures to grasp the nuances of the dataset, emphasizing key patterns and characteristics.

3. **Data Augmentation:**
    - Applied strategic data augmentation techniques to balance the dataset, mitigating potential class imbalances.

4. **Deep Neural Network Architecture:**
    - Devised a PyTorch-based DNN architecture tailored for handling multi-class classification, considering the unique characteristics of the dataset.

5. **Hyperparameter Tuning with GridSearch:**
    - Leveraged GridSearch for identifying optimal hyperparameters, enhancing model efficiency.

6. **Visualization:**
    - Presented visualizations of Loss vs. Epochs and Accuracy vs. Epochs for both training and test data.
    - Provided insightful interpretations based on discerned trends.

7. **Metrics Calculation:**
    - Computed key metrics, including accuracy, sensitivity, and F1 score, on both training and test datasets.

8. **Regularization Techniques:**
    - Applied an array of regularization techniques to the architecture.
    - Conducted a comparative analysis between results obtained with the initial, non-regularized model.

## Conclusion:
This immersive lab experience equipped us with valuable insights into the practical application of PyTorch for diverse tasks. The emphasis on exploratory data analysis, hyperparameter tuning, and model evaluation techniques underscored their critical role in achieving optimal model performance. The comparison before and after regularization offered valuable insights into the impact of these techniques on model robustness and generalization.
